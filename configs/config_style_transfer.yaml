
model:
  encoder_max_sequence_length: 2048
  decoder_max_sequence_length: 512
  encoder_num_layers: 12
  encoder_num_heads: 8
  encoder_hidden_size: 512
  encoder_intermediate_size: 2048
  decoder_num_layers: 12
  decoder_num_heads: 8
  decoder_hidden_size: 512
  decoder_intermediate_size: 2048

classifier_model:
  encoder_max_sequence_length: 1024
  encoder_num_layers: 12
  encoder_num_heads: 8
  encoder_hidden_size: 512
  encoder_intermediate_size: 2048
  encoder_dropout: 0.1

training:
  pretraining:
    epochs: 500
    batch_size: 4 #24
    learning_rate: 0.0001
    weight_decay: 0.01
    gradient_accumulation_steps: 1
    warmup_ratio: 0.3
    run_name: pre_trained_model
    run_pretraining: False
  fine_tuning:
    epochs: 3000
    batch_size: 4
    learning_rate: 0.00005
    weight_decay: 0.01
    gradient_accumulation_steps: 3
    warmup_ratio: 0.1
    run_name: fine_tuned_model
  classifier:
    epochs: 200
    batch_size: 64
    learning_rate: 0.0001
    weight_decay: 0.01
    gradient_accumulation_steps: 1
    warmup_ratio: 0.2
    run_name: classifier_model

generation:
  convert_from: classical
  convert_to: jazz # Choose from ['jazz', 'classical'].
  midi_file_path: "/input/debussy-clair-de-lune.mid"
  wav_file_path: "/input/debussy-clair-de-lune_original.wav"
  novel_peaks_pct: 0.05 # Percentage of novel peaks to be preserved.
  temperature: 1.0 # Temperature for sampling.
  context_before: 5 # Number of context frames before the corruption segment.
  context_after: 5 # Number of context frames after the corruption segment.
  t_segment_start: 2 # Start frame of the corruption segment. Each frame is 5 seconds long. For example, 2 corresponds to 0-10 seconds which would be preserved. The model will corrupt the next segment onwards.
  t_segment_stop: -1 # Stop frame of the corruption segment. Must be greater than t_segment_start. -1 will go to the end of the piece.
  end_original: True # If True, the model will use the original melody as the end of the harmony.
  write_intermediate_passes: True # If True, the model will write the intermediate passes to the output folder.
  passes:
    pass_1:
      corruption_rate: 1.0
      corruption_type: skyline
    pass_2:
      corruption_rate: 1.0
      corruption_type: skyline
    pass_3:
      corruption_rate: 0.5
      corruption_type: pitch_velocity_mask
    pass_4:
      corruption_rate: 0.5
      corruption_type: incorrect_transposition
    pass_5:
      corruption_rate: 0.5
      corruption_type: permute_pitches
    pass_6:
      corruption_rate: 0.5
      corruption_type: note_modification
    pass_7:
      corruption_rate: 1.0
      corruption_type: onset_duration_mask
    pass_8:
      corruption_rate: 0.5
      corruption_type: fragmentation
    pass_9:
      corruption_rate: 0.25
      corruption_type: whole_mask
    pass_10:
      corruption_rate: 0.25
      corruption_type: random

raw_data:
  raw_data_folders: 
    pre_training:
      folder_paths: ['/import/c4dm-datasets/aria/transcriptions/atepp', '/import/c4dm-datasets/aria/transcriptions/mazurkas']
      genre: classical
    fine_tuning:
      classical_folder_paths: ['/import/c4dm-datasets/maestro-v3.0.0']
      jazz_folder_paths: ['/import/c4dm-datasets/aria/transcriptions/pijama', '/import/c4dm-datasets-ext/doug_mcenzie_jazz']
      pop_folder_paths: ['/import/c4dm-datasets-ext/POP909']
  build_dataset: True
  artifact_folder: artifacts
  eval_folder: evaluations